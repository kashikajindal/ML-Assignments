{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "212a2c79-5a79-4084-beb8-4fa81449b54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - R2 Score: 0.9180\n",
      "Fold 2 - R2 Score: 0.9146\n",
      "Fold 3 - R2 Score: 0.9116\n",
      "Fold 4 - R2 Score: 0.9193\n",
      "Fold 5 - R2 Score: 0.9244\n",
      "\n",
      "Best R2 Score: 0.9243869413350316\n",
      "Final R2 Score on 30% test set: 0.9147458156636434\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "url = \"USA_Housing.csv\"   \n",
    "data = pd.read_csv(url)\n",
    "\n",
    "X = data.drop(columns=[\"Price\"])   \n",
    "y = data[\"Price\"].values.reshape(-1, 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "best_beta = None\n",
    "best_r2 = -np.inf\n",
    "\n",
    "fold = 1\n",
    "for train_index, test_index in kf.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    X_train_bias = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n",
    "    X_test_bias = np.c_[np.ones((X_test.shape[0], 1)), X_test]\n",
    "\n",
    "    beta = np.linalg.inv(X_train_bias.T @ X_train_bias) @ X_train_bias.T @ y_train\n",
    "\n",
    "    y_pred = X_test_bias @ beta\n",
    "\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"Fold {fold} - R2 Score: {r2:.4f}\")\n",
    "\n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        best_beta = beta\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "print(\"\\nBest R2 Score:\", best_r2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train_bias = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n",
    "X_test_bias = np.c_[np.ones((X_test.shape[0], 1)), X_test]\n",
    "\n",
    "y_pred_final = X_test_bias @ best_beta\n",
    "\n",
    "final_r2 = r2_score(y_test, y_pred_final)\n",
    "print(\"Final R2 Score on 30% test set:\", final_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4160bbb3-07dd-438b-be56-6d3bf47a7abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 0.001\n",
      "Validation R2: -1.0428, Test R2: -0.9601\n",
      "\n",
      "Learning Rate: 0.01\n",
      "Validation R2: 0.9199, Test R2: 0.9134\n",
      "\n",
      "Learning Rate: 0.1\n",
      "Validation R2: 0.9200, Test R2: 0.9134\n",
      "\n",
      "Learning Rate: 1\n",
      "Validation R2: 0.9200, Test R2: 0.9134\n",
      "\n",
      "Best Validation R2: 0.9199649194854793\n",
      "Best Beta Coefficients:\n",
      " [[1232180.27200919]\n",
      " [ 230645.88389435]\n",
      " [ 165328.94019375]\n",
      " [ 120045.00851908]\n",
      " [   2945.02108903]\n",
      " [ 151375.22971285]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "url = \"USA_Housing.csv\"  \n",
    "data = pd.read_csv(url)\n",
    "\n",
    "X = data.drop(columns=[\"Price\"])\n",
    "y = data[\"Price\"].values.reshape(-1, 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.44, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=(30/44), random_state=42)\n",
    "\n",
    "X_train_bias = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n",
    "X_val_bias = np.c_[np.ones((X_val.shape[0], 1)), X_val]\n",
    "X_test_bias = np.c_[np.ones((X_test.shape[0], 1)), X_test]\n",
    "\n",
    "def gradient_descent(X, y, alpha, iterations):\n",
    "    m, n = X.shape\n",
    "    beta = np.zeros((n, 1))\n",
    "\n",
    "    for i in range(iterations):\n",
    "        gradients = (1/m) * X.T @ (X @ beta - y)\n",
    "        beta = beta - alpha * gradients\n",
    "    \n",
    "    return beta\n",
    "\n",
    "learning_rates = [0.001, 0.01, 0.1, 1]\n",
    "best_beta = None\n",
    "best_r2_val = -np.inf\n",
    "\n",
    "for alpha in learning_rates:\n",
    "    beta = gradient_descent(X_train_bias, y_train, alpha, iterations=1000)\n",
    "\n",
    "    y_val_pred = X_val_bias @ beta\n",
    "    y_test_pred = X_test_bias @ beta\n",
    "\n",
    "    r2_val = r2_score(y_val, y_val_pred)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "    print(f\"Learning Rate: {alpha}\")\n",
    "    print(f\"Validation R2: {r2_val:.4f}, Test R2: {r2_test:.4f}\\n\")\n",
    "\n",
    "    if r2_val > best_r2_val:\n",
    "        best_r2_val = r2_val\n",
    "        best_beta = beta\n",
    "\n",
    "print(\"Best Validation R2:\", best_r2_val)\n",
    "print(\"Best Beta Coefficients:\\n\", best_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff74948e-25a0-4888-b9a5-902f0a56612c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (201, 29)\n",
      "R² Score (Original features): 0.8680\n",
      "R² Score (After PCA): 0.8596\n",
      "PCA did not improve performance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\AppData\\Local\\Temp\\ipykernel_27148\\2547014090.py:35: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[col] = data[col].astype(str).str.lower().replace(num_map)\n",
      "C:\\Users\\kashi\\AppData\\Local\\Temp\\ipykernel_27148\\2547014090.py:35: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[col] = data[col].astype(str).str.lower().replace(num_map)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\"\n",
    "columns = [\"symboling\", \"normalized_losses\", \"make\", \"fuel_type\", \"aspiration\",\n",
    "           \"num_doors\", \"body_style\", \"drive_wheels\", \"engine_location\", \"wheel_base\",\n",
    "           \"length\", \"width\", \"height\", \"curb_weight\", \"engine_type\", \"num_cylinders\",\n",
    "           \"engine_size\", \"fuel_system\", \"bore\", \"stroke\", \"compression_ratio\",\n",
    "           \"horsepower\", \"peak_rpm\", \"city_mpg\", \"highway_mpg\", \"price\"]\n",
    "\n",
    "data = pd.read_csv(url, names=columns)\n",
    "data = data.replace(\"?\", np.nan)\n",
    "\n",
    "\n",
    "data = data.dropna(subset=[\"price\"]).reset_index(drop=True)\n",
    "\n",
    "for col in data.columns:\n",
    "    if data[col].dtype == \"object\":\n",
    "        data[col] = data[col].fillna(data[col].mode()[0])\n",
    "    else:\n",
    "        data[col] = pd.to_numeric(data[col], errors=\"coerce\")\n",
    "        data[col] = data[col].fillna(data[col].median())\n",
    "\n",
    "\n",
    "num_map = {\"two\": 2, \"three\": 3, \"four\": 4, \"five\": 5,\n",
    "           \"six\": 6, \"eight\": 8, \"twelve\": 12}\n",
    "\n",
    "for col in [\"num_doors\", \"num_cylinders\"]:\n",
    "    if col in data.columns:\n",
    "        data[col] = data[col].astype(str).str.lower().replace(num_map)\n",
    "        data[col] = pd.to_numeric(data[col], errors=\"coerce\").fillna(0)\n",
    "\n",
    "\n",
    "if \"body_style\" in data.columns:\n",
    "    data = pd.get_dummies(data, columns=[\"body_style\"], drop_first=True)\n",
    "if \"drive_wheels\" in data.columns:\n",
    "    data = pd.get_dummies(data, columns=[\"drive_wheels\"], drop_first=True)\n",
    "\n",
    "\n",
    "for col in [\"make\", \"aspiration\", \"engine_location\", \"fuel_type\"]:\n",
    "    if col in data.columns:\n",
    "        le = LabelEncoder()\n",
    "        data[col] = le.fit_transform(data[col].astype(str))\n",
    "\n",
    "\n",
    "if \"fuel_system\" in data.columns:\n",
    "    data[\"fuel_system\"] = data[\"fuel_system\"].astype(str).str.lower().apply(lambda x: 1 if \"pfi\" in x else 0)\n",
    "\n",
    "\n",
    "if \"engine_type\" in data.columns:\n",
    "    data[\"engine_type\"] = data[\"engine_type\"].astype(str).str.lower().apply(lambda x: 1 if \"ohc\" in x else 0)\n",
    "\n",
    "X = data.drop(columns=[\"price\"])\n",
    "y = pd.to_numeric(data[\"price\"], errors=\"coerce\")\n",
    "\n",
    "X = X.apply(lambda col: pd.to_numeric(col, errors=\"coerce\")).fillna(0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"Feature matrix shape:\", X_scaled.shape)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "r2_original = r2_score(y_test, y_pred)\n",
    "print(f\"R² Score (Original features): {r2_original:.4f}\")\n",
    "\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "X_train_pca, X_test_pca, y_train, y_test = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n",
    "\n",
    "lr_pca = LinearRegression()\n",
    "lr_pca.fit(X_train_pca, y_train)\n",
    "y_pred_pca = lr_pca.predict(X_test_pca)\n",
    "r2_pca = r2_score(y_test, y_pred_pca)\n",
    "\n",
    "print(f\"R² Score (After PCA): {r2_pca:.4f}\")\n",
    "\n",
    "if r2_pca > r2_original:\n",
    "    print(\"PCA improved performance.\")\n",
    "else:\n",
    "    print(\"PCA did not improve performance.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deb3513-4214-4cac-a934-67c236dbfb68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
